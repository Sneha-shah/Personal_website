[{"categories":["Performance"],"contents":"To check out the Music Society of BITS Goa: https://www.youtube.com/c/MuSocBITSGoa\nRecreation of the Postmodern Jukebox arrangement of Creep by Radiohead. Recorded as part of the Music Society   Performance as part of Music Society annual performance. Played the keyboard for the Coke Studio version of the songs Nawazishein Karam + Tera Woh Pyaar   ","permalink":"https://sneha-shah.github.io/portfolio/performances-musoc/","tags":["Music","Performance"],"title":"Performances - Music Society"},{"categories":["Performance"],"contents":"To check out the Synchronoise acapella group of BITS Goa: https://www.youtube.com/c/SynchronoiseBITSGoaAcapella\nSong written and arranged for the acapella club, Synchronoise, to attract new students.   Acapella cover of Udd Gaye by Ritviz. Most popular youtube upload on Synchronoise youtube page.   Acapella performance of Hindi songs mashup. First acapella performance as part of the acapella club, Synchronoise.   First recording of an acapella song, Happy by Pharrell Williams, arrangement by Pentatonix.   Recording of Pass me the Jazz by The Real Group as part of the acapella club, Synchronoise.   Arrangement of the friends theme as part of the acapella club, Synchronoise.   ","permalink":"https://sneha-shah.github.io/portfolio/performances-synchro/","tags":["Music","Performance"],"title":"Performances - Synchronoise acapella group"},{"categories":["Performance"],"contents":"Recording of Schubert Impromptu Op. 90 No. 2 at Theme Kawai showroom, Bangalore. This piece is being prepared as part of Trinity performer\u0026rsquo;s exam, ATCL. Recorded at the Kawai showroom using a phone.   Recording of Chopin Fantaisie Impromptu at Theme Kawai showroom, Bangalore. This piece is being prepared as part of Trinity performer\u0026rsquo;s exam, ATCL. Recorded at the Kawai showroom using a phone.   Recording of the song Comptine d\u0026rsquo;un autre été by Yann Tiersen from the movie Amelie. Recorded at the Kawai showroom using a phone.   Recording of the popular piano song, River Flows Through You by Yiruma. Recorded at the Kawai showroom using a phone.   ","permalink":"https://sneha-shah.github.io/portfolio/piano-recordings/","tags":["Music","Performance"],"title":"Piano Recordings"},{"categories":["Performance"],"contents":"   ","permalink":"https://sneha-shah.github.io/portfolio/carrot-flute/","tags":["Music","Performance"],"title":"Carrot Flute"},{"categories":["Signal Processing"],"contents":"Update: Code added on github. Click here to view. This project was done as part of a research on volume expansion of a jaw after using arch expansion treatment. Worked with Doctor Pooja Radhakrishnan to identify the volume of a jaw from a 3D medical scan.\nStage 0: The initial plan was to manually mark edge points of jaw and calculate volume of the trapezoidal shape formed. However, this has large scope for manual error, and so other options had to be considered.\nStage 1: The first step in order to find the volume using MATLAB, was to separate the bone from the soft tissue in the CBCT scan. In this scan, the intensity value for each voxel is proportional to the density of the area being scanned. The bone has a higher intensity than soft tissue in the image. Therefore, I separated the bone by deciding a fixed intensity threshold. I later realised that a fixed threshold was not very accurate, and so changed it then.\nStage 2: The next step was to separate the jaw from the rest of the image. I tried multiple approaches; using segmentation algorithms, using the teeth as reference for the jaws, and slicing the image at fixed points. Uassing betweeltimately, the last one showed best results and so we used that. the upper jaw (Maxilla) was bounded on top by the nasal canal, and at the back by the bone of the lower jaw. The lower jaw (Mandible) was bounded at the back at the point where the upper end of the lower jaw began. The maxilla and mandible were separate by a plane passing between the jaws.\nStage 3: Once these steps were done, the volume of the remaining black and white image was to be found. The simplistic approach implemented was to find the number voxels set to 1. Without an idea of what value could be expected, it was unclear how accurate the results were. Once the pre and post scans were both available, we noticed that the volume difference calculated was erratic; ranging from 5 mm^2 to 2000 mm^2. A few values were also negative, proving that we needed more accurate volume calculation.\nStage 4: The first thing I noticed is that the pre and post scans were misaligned. And so I used registration to align the two images before the thresholding and segmenting steps conducted on each image with the same threshold values and cropping planes. While this improved the accuracy somewhat, we still received some negative and erratic values.\nStage 6: At this stage, I felt the need of expert guidance to move forward. I did feel that the thresholding method could be improved, as each image had different histograms. I contacted Professor Venkatesan Rajinikanth and informed him of our situation. He not only provided an improved thresholding algorithm, which was already helpful, but also suggested I use the Gray Level Co-Occurrence Matrix (GLCM) method that extracts details about texture, to find the volume of the bone.\nStage 7: An unexpected suggestion, I did my research on the topic and found that it might work. I am currently working on implementing this solution, and am confident that we will get accurate results using it. In the mean time, the results are also being calculated with the help of Materialise Mimics and Autodesk Meshmixer software.\n","permalink":"https://sneha-shah.github.io/portfolio/jaw-volume-calculation/","tags":["MATLAB","Signal Processing","Research"],"title":"Jaw Volume Calculation"},{"categories":["Signal Processing"],"contents":"Update: Code added on github. Click here to view. Using signal processing techniques to create an application to generate a real time pointer of the note (wrt Hindustani classical nomenclature) a person is singing, and a similar identification for a recorded song. Current model generates a rough graph which is accurate only for notes held longer. Working on accuracy of the identification by using different window types and sizes. Long term aim is to create a mobile application that helps beginner singers identify the accuracy of the note they are currently singing.\n","permalink":"https://sneha-shah.github.io/portfolio/note-identifier/","tags":["MATLAB","Signal Processing","Music","Research"],"title":"Note Identifier"},{"categories":["Software Programming"],"contents":"Used python and tkinter to create a GUI sudoku solver that combines manual and backtracking approaches for quicker solving. Currently, users have to manually enter given values in the sudoku, and so I am working on using computer vision to identify numbers from a written/printed sudoku using a camera.\nCheckout project on GitHub: https://github.com/Sneha-shah/sudoku-solver\nApproach Manual Approach: This solves the sudoku using methods similar to human solving. It checks every column, row, then box for missing numbers and fills it in if there is only one possible option. It failes for difficult sudokus that would require guessing by the solver.\nBacktracking Approach: This is a recursive approach to solve a sudoku. It guesses a number for each box and checks at every point if the rules are broken; if so, it backtracks and tries a different number. It is more thorough in the solving process and also identifies if there are multiple possible solutions. However, the time taken for this approach can be quite large.\nCombined Approach: In this program, a combined approach is taken where it solves the sudoku to the maximum possible point with the manual approach. When no more numbers can be added, it shifts to the backtracking approach. This ensures that the solving process takes less time than a purely backtracking approach.\nThe program has an option to solve sudoku using any one of the above approaches.\nTerminal interaction can be used to find multiple solutions. At the end of every solution found the recursive count and number of solutions found are displayed on the terminal.\n","permalink":"https://sneha-shah.github.io/portfolio/sudoku-solver/","tags":["Python","Game"],"title":"Sudoku Solver"},{"categories":["Signal Processing"],"contents":"Piano tuning is known to be difficult because the stiffness of piano strings causes the tones produced to be inharmonic. Aural tuning is time consuming and requires the help of a professional. This motivates the question of whether this process can be automated. Attempts at automatic tuning are usually assessed by comparing the Railsback curve of the results with the curve of a professional tuner.\nIn this project we determined a simple and reliable rule for tuning the high tones of a piano with the help of a listening test. This rule consists of matching the two tones in an octave interval so that the first partial frequency of the upper tone becomes exactly the same as the second partial frequency of the lower tone. This rule was rated best among four tuning rules that were compared in the test.\nThe results found are explained using a beat-based analysis, and are consistent with some previous studies. They are also tested against the existing method of using Railsback curves, and it is shown that comparison using Railsback curves is an unreliable method of assessing different tunings. The findings from this paper can be used to create a complete automatic tuner that could make the process of piano tuning quick and inexpensive.\nFor a detailed description of the work done, check out my Bachelor\u0026rsquo;s thesis.\nYou can find the paper published on this work here.\nWays to tune a piano Professional Tuner (Aural tuning)  This method has been used for centuries, and the art has been perfected over the years The complexity of the task means it cannot be done by a layman or even a musician not trained in the field  Computers (Automatic tuning)  This is a fairly new idea, which has not been explored to its full potential yet Current devices deliver unsatisfactory results and are not widely in use  Why is tuning a piano so difficult? Apart from the regular challenges of deciding what intervals to prioritise while tuning an instrument, the piano offers its own challenges.\n Piano strings are inharmonic; the partials of a tone are not exact multiples of the fundamental This means that target fundamental frequency of each tone is not fixed The strings get detuned with time, and so need to be tuned regularly  The method of aural tuning The tuning is based on the equal temperament scale. The process involves listening to different intervals on the piano and counting the beats produced. The target is to minimise the beats, which is done via the a specific process.\nThe process 1. Reference note is tuned to some frequency\n usually A4 tuned to 440 Hz concert pitches are often 442 or 443 Hz  2. Reference octave is tuned using this note\n uses many intervals starting from reference note octave is near the middle of piano used to tune rest of the piano (Add picture of reference octave here)  3. Upper half of the piano tuned using reference octave\n octaves used to tune also sometimes use other tests  4. Lower half of the piano tuned using reference octave\n Uses octaves and some larger intervals (Add picture of higher and lower octaves here)  Challenges of aural tuning  Time consuming and expensive Requires a professional or years of training  Automatic Tuning Steps  Input: Recorded untuned piano tones Intermediate: New fundamental frequencies of tones Output: Amount to turn tuning pin for tuned tones Action: Turning the tuning pin  Main challenge Finding new fundamental frequency Imitating results of aural tuning\nWhat makes it hard Inharmonicity of piano strings Subjectivity in aural tuning\nShortcomings of previous studies Quality of tuning compared with professional tuner  Visually using Railsback curves Calculating deviation of fundamental frequencies  Drawbacks  Subjectivity of professional tuning Compounding effect of tuning mistakes Not backed by any listening tests  Contribution 1. High Frequency Tones All analysis and results are for high piano tones Properties\n Have very high inharmonicity Few significant partials Fast decay Resonance in recording due to absence of damping Tuned using octaves  2. New Evaluation Method Beats based analysis Analyse beating effects for each octave Advantages\n Close to what professional tuners do Correlates with listening study  3. New Set of Recordings of Tuned Piano Tones Tones recorded on a Yamaha Disklavier\n4. Listening Study To find a simple tuning rule for high tones Compare different tuning analyses with results 4 tuning rules tested near 6th octave Multi Stimuli test with anchor 16 participants ( Add audio samples here)\nResults Methods:  Professional tuning (n) Geometric mean rule (gm) Matching first set of partials (m1) Matching second set of partials (m2) Matching third set of partials (m3)  (Add image)\nConclusion  Found simple rule for tuning high partials: Amongst the rules tested, matching the first set of partials scored the highest points in the listening test. Proposed new method to evaluate tuning: Proposed a beat-based approach that tries to mimic aural tuning, the results of which were confirmed by the listening test  ","permalink":"https://sneha-shah.github.io/portfolio/tuning-project/","tags":["Music","MATLAB","Signal Processing","Research","Thesis"],"title":"Automatic Piano Tuning"},{"categories":["Signal Processing"],"contents":"Automatic Classification of Bird Calls Project under Dr. Sarang C Dhongdi Jan 2019 – May 2019\n Studied algorithms that use signal processing techniques to identify bird species from their calls or songs, and learnt about transforms like the mel frequency cepstral coefficients. Implemented machine learning algorithms for the same using python. Learnt about convolutional neural networks and compared results with traditional algorithms using only signal processing methods.  Voice Scrambler and Unscrambler As Part of ’Digital Signal Processing’ Course Aug 2018 – Dec 2018\n Designed a system that scrambles and unscrambles voice signal for safe, loss­less transmission. The process primarily involved modulation with a key frequency, and included 2 low pass filters. The model was first tested on MATLAB and finally implemented on TI 6748 DSP kit. It was tested on recorded as well as real­time audio data. Correlation between original and scrambled signal was found to be 0.05, while correlation between original and unscrambled signal was found to be 0.98. Checkout the project report here  Spherical Harmonics and its Applications Project under Dr. Pradeep Boggarapu Jan 2019 – May 2019\n Mathematically studied spherical harmonics and their application in signal processing, specifically, head-related transfer functions (HRTF). Studied one paper that analyses the effect spatial smoothing has on the localization accuracy. It was done by systematically reducing the order of a spherical-harmonic-based HRTF representation. The results suggested that listeners do not rely on the fine details in an HRTF\u0026rsquo;s spatial structure and imply that some of the theoretically-derived bounds for HRTF sampling may be exceeding perceptual requirements. Checkout the project report here  ","permalink":"https://sneha-shah.github.io/portfolio/college-projects/","tags":["MATLAB","Signal Processing","Research"],"title":"College Projects"},{"categories":["Performance"],"contents":"               ","permalink":"https://sneha-shah.github.io/portfolio/instagram-uploads/","tags":["Music"],"title":"Instagram Uploads"},{"categories":["Software Programming"],"contents":"This is a mini imitation of the popular android game Cut The Rope using python. The game was created in high school for my 12th grade Computer Science project. It uses pygame for graphics and pictures from the original cut the rope to create our own game with 3 levels. I have used object oriented programming.\nProject link: https://drive.google.com/file/d/1CuilJbOxzlOl5AoV5rRIbKWK5Af5TV9V/view?usp=sharing Source code and screenshots on github: https://github.com/Sneha-shah/Cut-the-rope\nScreenshots of game Instructions Home Page Level Select Level 1 Level 2 Level 3 Game Over ","permalink":"https://sneha-shah.github.io/portfolio/cut-the-rope/","tags":["Python","Game"],"title":"Cut the Rope"},{"categories":["Software Programming"],"contents":"This project is a terminal imitation of the popular android game 2048. I wrote the code for this game using python in the 11th grade, for my Computer Science project. This game used modules like msvcrt and colorama along with clever substitutions to create a user-friendly gui.\nCheck out the game here: https://github.com/Sneha-shah/2048-game\nLearnings: As someone new to programming, I decided to write the logic and implement it myself. I later realised that the logic used was convoluted, and a lot of repetition could have been avoided with better structure and using object oriented programming. I also learnt how difficult it can be to make changes to an undocumented and unstructured code. This is a consideration I have kept in mind for later projects.\n","permalink":"https://sneha-shah.github.io/portfolio/2048/","tags":["Python","Game"],"title":"2048"}]